#  Predicci贸n de Accidente Cerebrovascular (ACV)
## Actividad Integradora - Comparaci贸n de Modelos Supervisados

**Dataset:** Stroke Prediction Dataset (Kaggle)  
**Modelos:** KNN, Perceptr贸n, MLP  
**Equipo:** Mes铆as Mariscal, Denise Rea, Julio Viche

---

## 1. Introducci贸n y Descripci贸n del Problema

### 1.1 Planteamiento del Problema

El **accidente cerebrovascular (ACV)** es una de las principales causas de muerte y discapacidad a nivel mundial. Seg煤n la Organizaci贸n Mundial de la Salud, aproximadamente 15 millones de personas sufren un ACV anualmente, y de ellos, 5 millones mueren y otros 5 millones quedan con discapacidad permanente. **Predecir el riesgo de ACV** es crucial para implementar intervenciones m茅dicas preventivas. Este proyecto busca desarrollar modelos de clasificaci贸n supervisada que, utilizando variables cl铆nicas como edad, hipertensi贸n, nivel de glucosa e IMC, puedan identificar pacientes con alto riesgo de sufrir un ACV, permitiendo a los profesionales de la salud tomar acciones preventivas oportunas.

### 1.2 Descripci贸n del Dataset

| Caracter铆stica | Valor |
|----------------|-------|
| **Nombre** | Stroke Prediction Dataset |
| **Fuente** | Kaggle |
| **Registros** | 5,110 |
| **Variables** | 12 (11 predictoras + 1 objetivo) |
| **Variable objetivo** | `stroke` (0 = No ACV, 1 = ACV) |

### 1.3 Variables del Dataset

| Variable | Tipo | Descripci贸n |
|----------|------|-------------|
| `id` | Num茅rica | Identificador 煤nico del paciente |
| `gender` | Categ贸rica | G茅nero del paciente (Male, Female, Other) |
| `age` | Num茅rica | Edad del paciente en a帽os |
| `hypertension` | Binaria | 0 = sin hipertensi贸n, 1 = con hipertensi贸n |
| `heart_disease` | Binaria | 0 = sin enfermedad card铆aca, 1 = con enfermedad |
| `ever_married` | Categ贸rica | Estado civil (Yes/No) |
| `work_type` | Categ贸rica | Tipo de empleo (Private, Self-employed, Govt_job, children, Never_worked) |
| `Residence_type` | Categ贸rica | Tipo de residencia (Urban/Rural) |
| `avg_glucose_level` | Num茅rica | Nivel promedio de glucosa en sangre (mg/dL) |
| `bmi` | Num茅rica | ndice de masa corporal |
| `smoking_status` | Categ贸rica | Estado de fumador (formerly smoked, never smoked, smokes, Unknown) |
| `stroke` | **Objetivo** | **1 = tuvo ACV, 0 = no tuvo ACV** |

---

## 3. EDA y Preprocesamiento

### 3.1 Carga y Exploraci贸n Inicial
- Se carg贸 el dataset y se revisaron dimensiones, columnas y primeras filas.
- Se analizaron tipos de datos y estad铆sticas descriptivas.

### 3.2 An谩lisis de Valores Faltantes
- Se identific贸 que la variable `bmi` ten铆a valores faltantes.
- Se imput贸 `bmi` con la mediana, por ser m谩s robusta ante outliers y adecuada para su distribuci贸n sesgada.

### 3.3 Distribuci贸n de la Variable Objetivo
- El dataset est谩 altamente desbalanceado: la clase positiva (stroke=1) es minoritaria.

### 3.4 Visualizaciones EDA
- Histogramas para `age`, `avg_glucose_level`, `bmi`.
- Gr谩ficos de barras para la variable objetivo y relaciones simples (`stroke` vs `hypertension`, `stroke` vs `smoking_status`).

### 3.5 Preprocesamiento de Datos
- Eliminaci贸n de columna `id`.
- Imputaci贸n de `bmi` con la mediana.
- Codificaci贸n One-Hot de variables categ贸ricas.
- Partici贸n estratificada 80/20 en train/test.
- Estandarizaci贸n de variables num茅ricas (`age`, `avg_glucose_level`, `bmi`) con StandardScaler.
- Balanceo de clases en entrenamiento usando SMOTE.

---

## 4. Modelos y Entrenamiento

Se entrenaron tres modelos con validaci贸n cruzada:
1. **KNN** con k = {3, 5, 7, 9, 11}
2. **Perceptr贸n** con diferentes `max_iter` y `eta0`
3. **MLP** con diferentes arquitecturas de capas ocultas

---

## 5. Evaluaci贸n y Comparaci贸n

- Se compararon los modelos usando Accuracy, Precision, Recall y F1-Score.
- Se prioriz贸 el Recall por el contexto cl铆nico (minimizar falsos negativos).
- Se presentaron matrices de confusi贸n y gr谩ficos comparativos.

---

## 6. Conclusiones y Modelo Recomendado

- El modelo recomendado fue seleccionado considerando m茅tricas y contexto cl铆nico.
- Se prioriz贸 el Recall para la clase positiva (stroke=1).
- Se justific贸 la elecci贸n considerando la importancia de minimizar falsos negativos.
- Se discutieron ventajas y limitaciones de cada modelo.

---

## Reflexi贸n sobre Preprocesamiento

- El escalado de variables fue fundamental para KNN y MLP.
- La imputaci贸n de valores faltantes evit贸 la p茅rdida de datos.
- El desbalance de clases afect贸 las m茅tricas; SMOTE mejor贸 el Recall.
- Se sugirieron posibles mejoras: feature engineering, probar otros algoritmos, ajustar umbral, validaci贸n externa.

---

## Resumen Final

| Aspecto | Descripci贸n |
|---------|-------------|
| **Dataset** | Stroke Prediction Dataset (5,110 registros, 12 variables) |
| **Preprocesamiento** | Imputaci贸n BMI (mediana), One-Hot Encoding, StandardScaler, SMOTE |
| **Modelos** | KNN (k 贸ptimo), Perceptr贸n (hiperpar谩metros 贸ptimos), MLP (arquitectura 贸ptima) |
| **M茅trica Principal** | Recall (contexto cl铆nico - detectar pacientes en riesgo) |
| **Validaci贸n** | Train/Test 80/20 estratificado + Cross-Validation 5-fold |

---

## Justificaci贸n del Modelo Recomendado

El modelo recomendado fue seleccionado considerando tanto las m茅tricas cuantitativas (recall, F1-score, accuracy, precision) como el contexto cl铆nico del problema. En la predicci贸n de ACV, el recall es especialmente importante, ya que permite identificar la mayor cantidad posible de pacientes en riesgo, minimizando los falsos negativos. Un falso negativo puede tener consecuencias graves en la salud del paciente, mientras que un falso positivo solo implica ex谩menes adicionales. Adem谩s, se consider贸 la estabilidad del modelo, su interpretabilidad y el balance entre precisi贸n y sensibilidad. Por estas razones, el modelo seleccionado ofrece el mejor compromiso entre desempe帽o y aplicabilidad cl铆nica.

- **M茅tricas clave:**
  - Recall y F1-score altos para la clase positiva (stroke=1)
  - Buen balance con precisi贸n y accuracy
- **Contexto cl铆nico:**
  - Prioridad en minimizar falsos negativos
  - Modelo robusto y aplicable en la pr谩ctica m茅dica
- **Otros factores:**
  - Interpretabilidad y facilidad de implementaci贸n
  - Costo computacional razonable

## Limitaciones y Posibles Mejoras

- **Desbalance de clases:** Aunque se aplic贸 SMOTE para balancear el conjunto de entrenamiento, el dataset original presenta una fuerte desproporci贸n entre clases. Esto puede afectar la generalizaci贸n del modelo y la interpretaci贸n de las m茅tricas.
- **Tama帽o del dataset:** El n煤mero de registros es limitado para un problema cl铆nico, lo que puede restringir la capacidad de los modelos para aprender patrones complejos y generalizar a nuevos datos.
- **Variables disponibles:** El dataset solo incluye variables cl铆nicas b谩sicas. Incluir informaci贸n adicional (historial m茅dico, h谩bitos, gen茅tica) podr铆a mejorar la predicci贸n.
- **Modelos probados:** Solo se evaluaron KNN, Perceptr贸n y MLP. Probar otros algoritmos como Random Forest, XGBoost o SVM podr铆a aportar mejoras.
- **Ajuste de umbral:** Se utiliz贸 el umbral est谩ndar de 0.5 para clasificaci贸n. Ajustar este valor podr铆a optimizar el recall o la precisi贸n seg煤n el objetivo cl铆nico.
- **Validaci贸n externa:** Los resultados deben validarse con datos de otros hospitales o cohortes para asegurar la robustez del modelo.

**Posibles mejoras:**
- Probar t茅cnicas avanzadas de balanceo de clases
- Realizar feature engineering para crear nuevas variables
- Ajustar hiperpar谩metros con b煤squeda m谩s exhaustiva
- Implementar interpretabilidad de modelos (SHAP, LIME)
- Validar el modelo en datos reales y prospectivos
