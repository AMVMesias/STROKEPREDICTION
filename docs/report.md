# üß† Predicci√≥n de Accidente Cerebrovascular (ACV)
## Actividad Integradora - Comparaci√≥n de Modelos Supervisados

**Dataset:** Stroke Prediction Dataset (Kaggle)  
**Modelos:** KNN, Perceptr√≥n, MLP  
**Equipo:** Mes√≠as Mariscal, Denise Rea, Julio Viche

---

## 1. Introducci√≥n y Descripci√≥n del Problema

### 1.1 Planteamiento del Problema

El **accidente cerebrovascular (ACV)** es una de las principales causas de muerte y discapacidad a nivel mundial. Seg√∫n la Organizaci√≥n Mundial de la Salud, aproximadamente 15 millones de personas sufren un ACV anualmente, y de ellos, 5 millones mueren y otros 5 millones quedan con discapacidad permanente. **Predecir el riesgo de ACV** es crucial para implementar intervenciones m√©dicas preventivas. Este proyecto busca desarrollar modelos de clasificaci√≥n supervisada que, utilizando variables cl√≠nicas como edad, hipertensi√≥n, nivel de glucosa e IMC, puedan identificar pacientes con alto riesgo de sufrir un ACV, permitiendo a los profesionales de la salud tomar acciones preventivas oportunas.

### 1.2 Descripci√≥n del Dataset

| Caracter√≠stica | Valor |
|----------------|-------|
| **Nombre** | Stroke Prediction Dataset |
| **Fuente** | Kaggle |
| **Registros** | 5,110 |
| **Variables** | 12 (11 predictoras + 1 objetivo) |
| **Variable objetivo** | `stroke` (0 = No ACV, 1 = ACV) |

### 1.3 Variables del Dataset

| Variable | Tipo | Descripci√≥n |
|----------|------|-------------|
| `id` | Num√©rica | Identificador √∫nico del paciente |
| `gender` | Categ√≥rica | G√©nero del paciente (Male, Female, Other) |
| `age` | Num√©rica | Edad del paciente en a√±os |
| `hypertension` | Binaria | 0 = sin hipertensi√≥n, 1 = con hipertensi√≥n |
| `heart_disease` | Binaria | 0 = sin enfermedad card√≠aca, 1 = con enfermedad |
| `ever_married` | Categ√≥rica | Estado civil (Yes/No) |
| `work_type` | Categ√≥rica | Tipo de empleo (Private, Self-employed, Govt_job, children, Never_worked) |
| `Residence_type` | Categ√≥rica | Tipo de residencia (Urban/Rural) |
| `avg_glucose_level` | Num√©rica | Nivel promedio de glucosa en sangre (mg/dL) |
| `bmi` | Num√©rica | √çndice de masa corporal |
| `smoking_status` | Categ√≥rica | Estado de fumador (formerly smoked, never smoked, smokes, Unknown) |
| `stroke` | **Objetivo** | **1 = tuvo ACV, 0 = no tuvo ACV** |

---

## 3. EDA y Preprocesamiento

### 3.1 Carga y Exploraci√≥n Inicial
- Se carg√≥ el dataset y se revisaron dimensiones, columnas y primeras filas.
- Se analizaron tipos de datos y estad√≠sticas descriptivas.

### 3.2 An√°lisis de Valores Faltantes
- Se identific√≥ que la variable `bmi` ten√≠a valores faltantes.
- Se imput√≥ `bmi` con la mediana, por ser m√°s robusta ante outliers y adecuada para su distribuci√≥n sesgada.

### 3.3 Distribuci√≥n de la Variable Objetivo
- El dataset est√° altamente desbalanceado: la clase positiva (stroke=1) es minoritaria.

### 3.4 Visualizaciones EDA
- Histogramas para `age`, `avg_glucose_level`, `bmi`.
- Gr√°ficos de barras para la variable objetivo y relaciones simples (`stroke` vs `hypertension`, `stroke` vs `smoking_status`).

### 3.5 Preprocesamiento de Datos
- Eliminaci√≥n de columna `id`.
- Imputaci√≥n de `bmi` con la mediana.
- Codificaci√≥n One-Hot de variables categ√≥ricas.
- Partici√≥n estratificada 80/20 en train/test.
- Estandarizaci√≥n de variables num√©ricas (`age`, `avg_glucose_level`, `bmi`) con StandardScaler.
- **Balanceo de clases:** Aplicaci√≥n de t√©cnicas espec√≠ficas seg√∫n el modelo (ver Secci√≥n 4).

---

## 4. Modelos y Entrenamiento

### 4.1 Estrategia de Configuraci√≥n: Priorizar Recall

En el contexto cl√≠nico de la predicci√≥n de ACV, **Recall es la m√©trica prioritaria**. Un falso negativo (no detectar un caso real de ACV) puede ser fatal, mientras que un falso positivo solo genera ex√°menes adicionales. Por esta raz√≥n, cada modelo fue configurado con una **combinaci√≥n espec√≠fica de escalador, balanceador y umbral** dise√±ada para maximizar la detecci√≥n de casos positivos.

### 4.2 Modelo 1: K-Nearest Neighbors (KNN)

**Configuraci√≥n:**
- **Escalador:** StandardScaler (normalizaci√≥n a media=0, std=1)
- **Balanceador:** RandomUnderSampler (reduce la clase mayoritaria para equilibrio)
- **Umbral de decisi√≥n:** 0.4 (favorece detecci√≥n sobre precisi√≥n)
- **Rango de k probado:** k = {3, 5, 7, 9, 11, 13, ..., 31}
- **M√©trica de selecci√≥n:** Recall (maximizar detecci√≥n de ACV)

**Justificaci√≥n:** RandomUnderSampler reduce la clase mayoritaria, permitiendo que KNN aprenda mejor de los casos minoritarios. El umbral reducido (0.4) aumenta la sensibilidad del modelo, detectando m√°s casos de ACV.

### 4.3 Modelo 2: Perceptr√≥n

**Configuraci√≥n:**
- **Escalador:** StandardScaler (normalizaci√≥n a media=0, std=1)
- **Balanceador:** SMOTE (genera ejemplos sint√©ticos de la clase minoritaria)
- **Umbral de decisi√≥n:** 0.5 (punto de equilibrio)
- **Hiperpar√°metros probados:** 4 configuraciones con diferentes `max_iter` y `eta0` (tasa de aprendizaje)
- **M√©trica de selecci√≥n:** Recall (maximizar detecci√≥n de ACV)

**Justificaci√≥n:** SMOTE crea datos sint√©ticos de la clase de ACV, enriqueciendo el conjunto de entrenamiento. El Perceptr√≥n, siendo un modelo lineal, es simple pero efectivo para este problema de clasificaci√≥n binaria.

### 4.4 Modelo 3: Red Neuronal (MLPClassifier)

**Configuraci√≥n:**
- **Escalador:** StandardScaler (normalizaci√≥n a media=0, std=1)
- **Balanceador:** RandomUnderSampler (reduce la clase mayoritaria)
- **Arquitecturas probadas:** 4 configuraciones de capas ocultas:
  - (16,) con ReLU
  - (32, 16) con ReLU
  - (64, 32) con ReLU
  - (32, 16) con Tanh
- **Early Stopping:** Evita overfitting usando validaci√≥n interna
- **M√©trica de selecci√≥n:** Recall (maximizar detecci√≥n de ACV)

**Justificaci√≥n:** MLP captura patrones no lineales complejos. Random Undersampling balancea las clases, permitiendo que la red neuronal aprenda mejor de ambas clases.

---

## 5. Evaluaci√≥n y Comparaci√≥n

### 5.1 M√©tricas Utilizadas

Para cada modelo se calcularon las siguientes m√©tricas en el conjunto de prueba:
- **Accuracy:** Proporci√≥n de predicciones correctas (ambas clases)
- **Precision:** Proporci√≥n de casos positivos predichos que fueron correctos
- **Recall:** Proporci√≥n de casos positivos reales que fueron detectados
- **F1-Score:** Media arm√≥nica entre Precision y Recall

### 5.2 Estrategia de Comparaci√≥n

La comparaci√≥n fue realizada con un **enfoque ponderado priorizando Recall:**
- **Recall:** 40% (maximizar detecci√≥n de ACV)
- **F1-Score:** 30% (balance entre Precision y Recall)
- **Precision:** 20% (minimizar alarmas falsas)
- **Accuracy:** 10% (rendimiento general)

Esta ponderaci√≥n refleja la importancia cl√≠nica de detectar casos de ACV sobre otras consideraciones.

### 5.3 Resultados y An√°lisis

Se presentan:
- Tabla comparativa de m√©tricas para los tres modelos
- Matrices de confusi√≥n para visualizar verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos
- Gr√°ficos comparativos de desempe√±o
- Classification reports con m√©tricas por clase

**Hallazgos clave:**
- El model con mayor Recall fue identificado y recomendado
- Se observ√≥ trade-off entre Precision y Recall (esperado en datasets desbalanceados)
- La ponderaci√≥n de Recall reflej√≥ correctamente la prioridad cl√≠nica

---

## 6. Conclusiones y Resultados Finales

### 6.1 Resultados de la Evaluaci√≥n Final

Los tres modelos supervisados fueron evaluados en el conjunto de prueba utilizando sus mejores configuraciones de preprocesamiento identificadas en la Secci√≥n 4. Los resultados finales son:

| Modelo | Accuracy | Precision | Recall | F1-Score | Score Ponderado |
|--------|----------|-----------|--------|----------|-----------------|
| KNN (k=5) | 0.6546 | 0.0938 | 0.7000 | 0.1655 | 0.5290 |
| Perceptr√≥n | 0.0577 | 0.0494 | 1.0000 | 0.0941 | 0.4396 |
| **MLP (64, 32)** | **0.6399** | **0.1025** | **0.8200** | **0.1822** | **0.5714** ‚úì |

**Nota:** El Score Ponderado se calcula como:
$$\text{Score} = 0.40 \times \text{Recall} + 0.30 \times \text{F1-Score} + 0.20 \times \text{Precision} + 0.10 \times \text{Accuracy}$$

### 6.2 An√°lisis por M√©trica

| M√©trica | Mejor Modelo | Valor | Interpretaci√≥n |
|---------|-------------|-------|-----------------|
| **Accuracy** | KNN (k=5) | 0.6546 | 65.46% de predicciones totalmente correctas |
| **Precision** | MLP (64, 32) | 0.1025 | De cada 100 alertas de ACV, ~10 son correctas |
| **Recall** | Perceptr√≥n | 1.0000 | Detecta 100% de casos reales (pero con Accuracy terrible) |
| **F1-Score** | MLP (64, 32) | 0.1822 | Mejor balance Precision-Recall |
| **Score Ponderado** | **MLP (64, 32)** | **0.5714** | **Mejor desempe√±o global considerando contexto cl√≠nico** |

### 6.3 Modelo Recomendado: MLP (64, 32)

**‚úì RECOMENDACI√ìN: Red Neuronal con arquitectura (64, 32)**

**Justificaci√≥n:**
1. **Score Ponderado m√°ximo** (0.5714): Mejor equilibrio considerando todos los factores
2. **Recall robusto** (0.8200): Detecta 82% de casos reales de ACV
3. **F1-Score √≥ptimo** (0.1822): Mejor balance Precision-Recall que otros modelos
4. **Arquitectura efectiva**: Capas (64, 32) capturan patrones no-lineales complejos
5. **Configuraci√≥n balanceada**: RandomUnderSampler + StandardScaler favorece Recall sin colapsar Accuracy

**¬øPor qu√© no los otros modelos?**
- **KNN (k=5)**: Accuracy similar pero Recall e inferior (0.70), F1-Score bajo (0.1655), Score ponderado menor (0.5290)
- **Perceptr√≥n**: Recall perfecto (1.0) pero Accuracy catastr√≥fico (5.77%), implica que predice casi siempre "ACV"

### 6.4 Justificaci√≥n de la Priorizaci√≥n de Recall

En el contexto cl√≠nico de la predicci√≥n de ACV:

- **Falso Negativo (no detectar un ACV real):** Riesgo potencial de **muerte o discapacidad grave** del paciente. Consecuencia **inaceptable**.
- **Falso Positivo (alerta falsa de ACV):** Solo requiere **ex√°menes adicionales**. Consecuencia **aceptable** desde perspectiva m√©dica.

Con el modelo MLP recomendado:
- De 100 pacientes que tienen ACV real ‚Üí Detecta ~82 (18 pueden no ser detectados = RIESGO)
- De 100 pacientes sin ACV ‚Üí ~90 falsas alertas (ex√°menes innecesarios = costo)

El trade-off es aceptable porque la vida del paciente es prioritaria.

### 6.5 M√©tricas Detalladas por Modelo

#### KNN (k=5)
- **Configuraci√≥n:** StandardScaler + RandomUnderSampler + threshold 0.4
- **Fortalezas:** Buena Accuracy (65.46%), simple e interpretable, Precision moderada (9.38%)
- **Debilidades:** Recall moderado (70%), sensible al escalado de variables

#### Perceptr√≥n
- **Configuraci√≥n:** StandardScaler + SMOTE + threshold 0.5
- **Fortalezas:** Detecta todos los casos de ACV (Recall=100%)
- **Debilidades:** Accuracy muy baja (5.77%), esencialmente predice siempre "ACV"

#### MLP (64, 32) ‚úì RECOMENDADO
- **Configuraci√≥n:** StandardScaler + RandomUnderSampler + arquitectura (64, 32)
- **Fortalezas:** F1-Score √≥ptimo (0.1822), Score m√°ximo (0.5714), Recall alto (0.82)
- **Debilidades:** Menos interpretable que KNN, requiere m√°s datos para entrenar

### 6.6 Limitaciones y Recomendaciones de Uso

**Limitaciones del modelo:**
1. Dataset originalmente muy desbalanceado (95% vs 5%) ‚Üí se us√≥ SMOTE/RandomUnderSampler
2. Tama√±o de muestra peque√±o (5,110 registros) para redes neuronales
3. Variables faltantes en BMI (~4%) imputadas con mediana
4. Validaci√≥n solo en subset de prueba, no en datos externos

**Recomendaciones de implementaci√≥n:**
- ‚úì Usar como **sistema de apoyo a decisiones m√©dicas**, no como diagn√≥stico definitivo
- ‚úì Generar **alertas tempranas** para revisi√≥n m√©dica posterior
- ‚úì Aplicar **umbral de confianza** m√≠nima (ej. predicci√≥n > 0.5)
- ‚úó **NO usar como diagn√≥stico definitivo** ‚Üí requiere evaluaci√≥n cl√≠nica
- ‚úì Reentrenar peri√≥dicamente con datos nuevos
- ‚úì Validar resultados con especialistas m√©dicos antes de implementaci√≥n
- ‚úì Usar con datos de m√∫ltiples hospitales/cohortes para mayor robustez

**Posibles mejoras futuras:**
- Probar algoritmos avanzados (Random Forest, XGBoost, SVM)
- Feature engineering: crear variables compuestas (age√óhypertension, etc.)
- Ajustar umbral de clasificaci√≥n seg√∫n objetivo cl√≠nico espec√≠fico
- Recopilar datos prospectivos para validaci√≥n externa
- Implementar interpretabilidad (SHAP, LIME) para explicabilidad m√©dica

---

## Reflexi√≥n sobre Preprocesamiento

### ¬øQu√© ocurri√≥ antes y despu√©s de escalar?

**Antes del escalado:**
- Variables con rangos diferentes: `age` (0-82), `avg_glucose_level` (55-270), `bmi` (10-60)
- KNN: La distancia euclidiana era dominada por variables con rangos mayores
- MLP: Gradientes inestables, convergencia lenta

**Despu√©s del escalado (StandardScaler):**
- Todas las variables con media ‚âà 0 y desviaci√≥n est√°ndar ‚âà 1
- KNN: Distancia euclidiana equilibrada entre todas las dimensiones
- MLP: Gradientes estables, convergencia m√°s r√°pida y efectiva

### ¬øQu√© suceder√≠a sin imputaci√≥n de valores faltantes?

- **P√©rdida de datos:** ~200 registros con BMI faltante ser√≠an descartados (‚âà4% del dataset)
- **Reducci√≥n de informaci√≥n:** Menos datos para entrenar, especialmente en la clase minoritaria (ACV)
- **Error en sklearn:** Las funciones de sklearn lanzan excepciones con valores NaN
- **Imputaci√≥n con mediana:** Preserva la distribuci√≥n de datos y es robusta ante outliers

### ¬øEl desbalance de clases afect√≥ las m√©tricas?

**S√≠, significativamente:**

**Sin balanceo:**
- El modelo predec√≠a principalmente clase 0 (no ACV)
- Recall para ACV = 0% (nunca predec√≠a positivos)
- Accuracy muy alto (~95%) pero **completamente enga√±oso**
- Problema: Falsos negativos catastr√≥ficos

**Con balanceo (RandomUnderSampler / SMOTE):**
- Los modelos aprenden patrones de la clase minoritaria
- Recall mejora significativamente (hasta 100% en Perceptr√≥n, 82% en MLP)
- Precision disminuye ligeramente (trade-off esperado)
- Resultado: Mejor balance cl√≠nico, mayor utilidad pr√°ctica

### Impacto de las T√©cnicas de Balanceo por Modelo

- **RandomUnderSampler (KNN, MLP):** Reduce clase mayoritaria; r√°pido, pero pierde datos
- **SMOTE (Perceptr√≥n):** Genera datos sint√©ticos; preserva informaci√≥n, pero aumenta varianza
- **Selecci√≥n:** Cada modelo us√≥ la t√©cnica que maximizaba su Recall en validaci√≥n cruzada

---

## Resumen Final

| Aspecto | Descripci√≥n |
|---------|-------------|
| **Dataset** | Stroke Prediction Dataset (5,110 registros, 12 variables) |
| **Preprocesamiento** | Imputaci√≥n BMI (mediana), One-Hot Encoding, StandardScaler, Balanceadores espec√≠ficos |
| **Modelos** | KNN (RandomUnderSampler, threshold 0.4), Perceptr√≥n (SMOTE, threshold 0.5), MLP (RandomUnderSampler) |
| **M√©trica Principal** | Recall (contexto cl√≠nico - detectar pacientes con riesgo real de ACV) |
| **Ponderaci√≥n de M√©tricas** | Recall: 40%, F1-Score: 30%, Precision: 20%, Accuracy: 10% |
| **Validaci√≥n** | Train/Test 80/20 estratificado + Validaci√≥n cruzada 5-fold |

---

## Justificaci√≥n del Modelo Recomendado

El modelo recomendado fue seleccionado mediante una evaluaci√≥n sistem√°tica que prioriz√≥ el **Recall como m√©trica clave**, considerando tanto aspectos cuantitativos como cualitativos.

### Criterios de Selecci√≥n

**1. Contexto Cl√≠nico (Prioritario)**
- En la predicci√≥n de ACV, detectar el m√°ximo de casos reales es cr√≠tico
- El costo de un falso negativo (paciente con ACV no detectado) es **potencialmente la vida del paciente**
- El costo de un falso positivo es **ex√°menes adicionales** (aceptable cl√≠nicamente)

**2. M√©tricas de Desempe√±o**
- **Recall:** M√°xima capacidad de detecci√≥n de pacientes con ACV real
- **F1-Score:** Balance equilibrado entre Precision y Recall
- **Accuracy:** Rendimiento general aceptable
- **Precision:** Minimizaci√≥n de alarmas falsas

**3. Caracter√≠sticas del Modelo**
- Estabilidad y robustez en validaci√≥n cruzada
- Interpretabilidad y facilidad de implementaci√≥n
- Costo computacional y tiempo de predicci√≥n razonable
- Reproducibilidad de resultados

### Ponderaci√≥n de M√©tricas

La evaluaci√≥n final utiliz√≥ la siguiente ponderaci√≥n:

$$\text{Score} = 0.40 \times \text{Recall} + 0.30 \times \text{F1-Score} + 0.20 \times \text{Precision} + 0.10 \times \text{Accuracy}$$

Esta f√≥rmula refuerza la importancia cl√≠nica de Recall mientras mantiene un balance con otras m√©tricas relevantes.

### Recomendaci√≥n Final

El modelo seleccionado **ofrece el mejor compromiso entre desempe√±o y aplicabilidad cl√≠nica**, permitiendo:
- M√°xima detecci√≥n de pacientes con riesgo real de ACV
- Intervenciones preventivas oportunas
- Apoyo confiable para profesionales de la salud en la toma de decisiones

## Limitaciones y Posibles Mejoras

- **Desbalance de clases:** Aunque se aplic√≥ SMOTE para balancear el conjunto de entrenamiento, el dataset original presenta una fuerte desproporci√≥n entre clases. Esto puede afectar la generalizaci√≥n del modelo y la interpretaci√≥n de las m√©tricas.
- **Tama√±o del dataset:** El n√∫mero de registros es limitado para un problema cl√≠nico, lo que puede restringir la capacidad de los modelos para aprender patrones complejos y generalizar a nuevos datos.
- **Variables disponibles:** El dataset solo incluye variables cl√≠nicas b√°sicas. Incluir informaci√≥n adicional (historial m√©dico, h√°bitos, gen√©tica) podr√≠a mejorar la predicci√≥n.
- **Modelos probados:** Solo se evaluaron KNN, Perceptr√≥n y MLP. Probar otros algoritmos como Random Forest, XGBoost o SVM podr√≠a aportar mejoras.
- **Ajuste de umbral:** Se utiliz√≥ el umbral est√°ndar de 0.5 para clasificaci√≥n. Ajustar este valor podr√≠a optimizar el recall o la precisi√≥n seg√∫n el objetivo cl√≠nico.
- **Validaci√≥n externa:** Los resultados deben validarse con datos de otros hospitales o cohortes para asegurar la robustez del modelo.

**Posibles mejoras:**
- Probar t√©cnicas avanzadas de balanceo de clases
- Realizar feature engineering para crear nuevas variables
- Ajustar hiperpar√°metros con b√∫squeda m√°s exhaustiva
- Implementar interpretabilidad de modelos (SHAP, LIME)
- Validar el modelo en datos reales y prospectivos
